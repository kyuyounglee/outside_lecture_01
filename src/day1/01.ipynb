{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "acf45ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-core in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_1\\lib\\site-packages (0.3.61)\n",
      "Requirement already satisfied: langchain in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_1\\lib\\site-packages (0.3.25)\n",
      "Requirement already satisfied: langchain-openai in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_1\\lib\\site-packages (0.3.18)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_1\\lib\\site-packages (1.1.0)\n",
      "Collecting langchain_community\n",
      "  Downloading langchain_community-0.3.24-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.126 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_1\\lib\\site-packages (from langchain-core) (0.3.42)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_1\\lib\\site-packages (from langchain-core) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_1\\lib\\site-packages (from langchain-core) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_1\\lib\\site-packages (from langchain-core) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_1\\lib\\site-packages (from langchain-core) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_1\\lib\\site-packages (from langchain-core) (4.13.2)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_1\\lib\\site-packages (from langchain-core) (2.11.5)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_1\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_1\\lib\\site-packages (from langsmith<0.4,>=0.1.126->langchain-core) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_1\\lib\\site-packages (from langsmith<0.4,>=0.1.126->langchain-core) (3.10.18)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_1\\lib\\site-packages (from langsmith<0.4,>=0.1.126->langchain-core) (2.32.3)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_1\\lib\\site-packages (from langsmith<0.4,>=0.1.126->langchain-core) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_1\\lib\\site-packages (from langsmith<0.4,>=0.1.126->langchain-core) (0.23.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_1\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.126->langchain-core) (4.9.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_1\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.126->langchain-core) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_1\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.126->langchain-core) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_1\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.126->langchain-core) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_1\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.126->langchain-core) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_1\\lib\\site-packages (from pydantic>=2.7.4->langchain-core) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_1\\lib\\site-packages (from pydantic>=2.7.4->langchain-core) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_1\\lib\\site-packages (from pydantic>=2.7.4->langchain-core) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_1\\lib\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.126->langchain-core) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_1\\lib\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.126->langchain-core) (2.4.0)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_1\\lib\\site-packages (from langchain) (0.3.8)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_1\\lib\\site-packages (from langchain) (2.0.41)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_1\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.2)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.68.2 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_1\\lib\\site-packages (from langchain-openai) (1.82.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_1\\lib\\site-packages (from langchain-openai) (0.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_1\\lib\\site-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_1\\lib\\site-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (0.10.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_1\\lib\\site-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_1\\lib\\site-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (4.67.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_1\\lib\\site-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain_community)\n",
      "  Downloading aiohttp-3.11.18-cp312-cp312-win_amd64.whl.metadata (8.0 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
      "  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
      "  Using cached pydantic_settings-2.9.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain_community)\n",
      "  Using cached httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting numpy>=1.26.2 (from langchain_community)\n",
      "  Downloading numpy-2.2.6-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Using cached aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_1\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Using cached frozenlist-1.6.0-cp312-cp312-win_amd64.whl.metadata (16 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Downloading multidict-6.4.4-cp312-cp312-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Using cached propcache-0.3.1-cp312-cp312-win_amd64.whl.metadata (11 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Using cached yarl-1.20.0-cp312-cp312-win_amd64.whl.metadata (74 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Using cached marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_1\\lib\\site-packages (from tqdm>4->openai<2.0.0,>=1.68.2->langchain-openai) (0.4.6)\n",
      "Downloading langchain_community-0.3.24-py3-none-any.whl (2.5 MB)\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.5/2.5 MB 73.1 MB/s eta 0:00:00\n",
      "Downloading aiohttp-3.11.18-cp312-cp312-win_amd64.whl (439 kB)\n",
      "Using cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Using cached httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Using cached marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Downloading multidict-6.4.4-cp312-cp312-win_amd64.whl (38 kB)\n",
      "Using cached pydantic_settings-2.9.1-py3-none-any.whl (44 kB)\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Using cached yarl-1.20.0-cp312-cp312-win_amd64.whl (92 kB)\n",
      "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Using cached aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached frozenlist-1.6.0-cp312-cp312-win_amd64.whl (120 kB)\n",
      "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Downloading numpy-2.2.6-cp312-cp312-win_amd64.whl (12.6 MB)\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ----------------------------- ---------- 9.4/12.6 MB 84.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.6/12.6 MB 37.7 MB/s eta 0:00:00\n",
      "Using cached propcache-0.3.1-cp312-cp312-win_amd64.whl (44 kB)\n",
      "Installing collected packages: propcache, numpy, mypy-extensions, multidict, marshmallow, httpx-sse, frozenlist, aiohappyeyeballs, yarl, typing-inspect, aiosignal, pydantic-settings, dataclasses-json, aiohttp, langchain_community\n",
      "\n",
      "   -- -------------------------------------  1/15 [numpy]\n",
      "   -- -------------------------------------  1/15 [numpy]\n",
      "   -- -------------------------------------  1/15 [numpy]\n",
      "   -- -------------------------------------  1/15 [numpy]\n",
      "   -- -------------------------------------  1/15 [numpy]\n",
      "   -- -------------------------------------  1/15 [numpy]\n",
      "   -- -------------------------------------  1/15 [numpy]\n",
      "   -- -------------------------------------  1/15 [numpy]\n",
      "   -- -------------------------------------  1/15 [numpy]\n",
      "   -- -------------------------------------  1/15 [numpy]\n",
      "   -------- -------------------------------  3/15 [multidict]\n",
      "   ----------------------------- ---------- 11/15 [pydantic-settings]\n",
      "   ---------------------------------- ----- 13/15 [aiohttp]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ---------------------------------------- 15/15 [langchain_community]\n",
      "\n",
      "Successfully installed aiohappyeyeballs-2.6.1 aiohttp-3.11.18 aiosignal-1.3.2 dataclasses-json-0.6.7 frozenlist-1.6.0 httpx-sse-0.4.0 langchain_community-0.3.24 marshmallow-3.26.1 multidict-6.4.4 mypy-extensions-1.1.0 numpy-2.2.6 propcache-0.3.1 pydantic-settings-2.9.1 typing-inspect-0.9.0 yarl-1.20.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain-core langchain langchain-openai python-dotenv langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093592e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sk-proj-Do'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "# .env íŒŒì¼ì„ ë§Œë“¤ì–´ì„œ OPENAI_API_KEY= ... í˜•íƒœë¡œ ì‘ì„±ë˜ì–´ì•¼ í•¨\n",
    "load_dotenv()\n",
    "os.getenv('OPENAI_API_KEY')[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c334fe91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is a good name for a company that makes coffee?\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜: {product} ë¶€ë¶„ì´ ì´í›„ì— ì±„ì›Œì§ˆ í”Œë ˆì´ìŠ¤í™€ë”ì…ë‹ˆë‹¤.\n",
    "template = \"What is a good name for a company that makes {product}?\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# í…œí”Œë¦¿ì— ê°’ì„ ì±„ì›Œ ì‹¤ì œ í”„ë¡¬í”„íŠ¸ ìƒì„±\n",
    "formatted_prompt = prompt.format(product=\"coffee\")\n",
    "print(formatted_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db5170e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì»¤í”¼ë¼ëŠ” ë§Œë“œëŠ” íšŒì‚¬ ì´ë¦„ìœ¼ë¡œ ì–´ë–¤ê²Œ ì¢‹ì„ê¹Œ?\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜: {product} ë¶€ë¶„ì´ ì´í›„ì— ì±„ì›Œì§ˆ í”Œë ˆì´ìŠ¤í™€ë”ì…ë‹ˆë‹¤.\n",
    "template = \"{product}ë¼ëŠ” ë§Œë“œëŠ” íšŒì‚¬ ì´ë¦„ìœ¼ë¡œ ì–´ë–¤ê²Œ ì¢‹ì„ê¹Œ?\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# í…œí”Œë¦¿ì— ê°’ì„ ì±„ì›Œ ì‹¤ì œ í”„ë¡¬í”„íŠ¸ ìƒì„±\n",
    "formatted_prompt = prompt.format(product=\"ì»¤í”¼\")\n",
    "print(formatted_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88e494a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='ì»¤í”¼ íšŒì‚¬ ì´ë¦„ì„ ì •í•  ë•ŒëŠ” ë¸Œëœë“œì˜ ì´ë¯¸ì§€, íƒ€ê²Ÿ ê³ ê°, ê·¸ë¦¬ê³  ì œí’ˆì˜ íŠ¹ì§•ì„ ê³ ë ¤í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤. ë‹¤ìŒì€ ëª‡ ê°€ì§€ ì•„ì´ë””ì–´ì…ë‹ˆë‹¤:\\n\\n1. **ì»¤í”¼ì˜ ì •ì›** - ìì—° ì¹œí™”ì ì¸ ëŠë‚Œì„ ì£¼ëŠ” ì´ë¦„\\n2. **ì•„ì¹¨ì˜ í•œ ì”** - ì•„ì¹¨ì— ì»¤í”¼ë¥¼ ì¦ê¸°ëŠ” ì‚¬ëŒë“¤ì„ ê²¨ëƒ¥í•œ ì´ë¦„\\n3. **ì»¤í”¼ì˜ í–¥ê¸°** - ì»¤í”¼ì˜ í’ë¯¸ì™€ í–¥ì„ ê°•ì¡°í•œ ì´ë¦„\\n4. **ì»¤í”¼ ì´ì•¼ê¸°** - ê° ì»¤í”¼ì˜ ë°°ê²½ê³¼ ìŠ¤í† ë¦¬ë¥¼ ê°•ì¡°í•˜ëŠ” ì´ë¦„\\n5. **í•œ ì”ì˜ ì—¬ìœ ** - ì—¬ìœ ë¡œìš´ ì»¤í”¼ íƒ€ì„ì„ ìƒì§•í•˜ëŠ” ì´ë¦„\\n6. **ì»¤í”¼ ê³µë°©** - ìˆ˜ì œ ì»¤í”¼ì˜ ëŠë‚Œì„ ì£¼ëŠ” ì´ë¦„\\n7. **ì»¤í”¼ ë§ˆì„** - ë‹¤ì–‘í•œ ì»¤í”¼ë¥¼ ì œê³µí•˜ëŠ” ëŠë‚Œì„ ì£¼ëŠ” ì´ë¦„\\n8. **ì»¤í”¼ì˜ ë¯¸ì†Œ** - ì¦ê±°ìš´ ì»¤í”¼ ê²½í—˜ì„ ê°•ì¡°í•˜ëŠ” ì´ë¦„\\n9. **ì»¤í”¼ì˜ ì‹œê°„** - ì»¤í”¼ì™€ í•¨ê»˜í•˜ëŠ” íŠ¹ë³„í•œ ìˆœê°„ì„ ê°•ì¡°í•˜ëŠ” ì´ë¦„\\n10. **ì»¤í”¼ì˜ ì˜ˆìˆ ** - ì»¤í”¼ë¥¼ ì˜ˆìˆ ë¡œ í‘œí˜„í•˜ëŠ” ëŠë‚Œì˜ ì´ë¦„\\n\\nì´ ì¤‘ì—ì„œ ë§ˆìŒì— ë“œëŠ” ì´ë¦„ì´ ìˆê±°ë‚˜, ì¡°í•©í•˜ì—¬ ìƒˆë¡œìš´ ì´ë¦„ì„ ë§Œë“¤ì–´ë³´ëŠ” ê²ƒë„ ì¢‹ìŠµë‹ˆë‹¤!' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 282, 'prompt_tokens': 20, 'total_tokens': 302, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_54eb4bd693', 'id': 'chatcmpl-BaacNWqfS05J6oWT2MucRK0jw4FiY', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--32a0037c-19b1-4ed4-b570-e12e49bc4314-0' usage_metadata={'input_tokens': 20, 'output_tokens': 282, 'total_tokens': 302, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# OpenAI ì±— ëª¨ë¸ ë˜í¼ ìƒì„± (GPT-4o-mini ëª¨ë¸ ì‚¬ìš©, ì˜¨ë„=0ìœ¼ë¡œ ì„¤ì •í•˜ì—¬ ê²°ì •ë¡ ì  ì‘ë‹µ)\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# ì˜ˆì‹œ ë©”ì‹œì§€ë¥¼ ëª¨ë¸ì— ë³´ë‚´ë³´ê¸° (ì—­í• : human, ë‚´ìš©: ì¸ì‚¬ë§)\n",
    "response = llm.invoke([(\"human\", formatted_prompt)])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b39f7787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì»¤í”¼ íšŒì‚¬ ì´ë¦„ì„ ì •í•  ë•ŒëŠ” ë¸Œëœë“œì˜ ì´ë¯¸ì§€, íƒ€ê²Ÿ ê³ ê°, ê·¸ë¦¬ê³  ì œí’ˆì˜ íŠ¹ì§•ì„ ê³ ë ¤í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤. ë‹¤ìŒì€ ëª‡ ê°€ì§€ ì•„ì´ë””ì–´ì…ë‹ˆë‹¤:\n",
      "\n",
      "1. **ì»¤í”¼ì˜ ì •ì›** - ìì—° ì¹œí™”ì ì¸ ëŠë‚Œì„ ì£¼ëŠ” ì´ë¦„\n",
      "2. **ì•„ì¹¨ì˜ í•œ ì”** - ì•„ì¹¨ì— ì»¤í”¼ë¥¼ ì¦ê¸°ëŠ” ì‚¬ëŒë“¤ì„ ê²¨ëƒ¥í•œ ì´ë¦„\n",
      "3. **ì»¤í”¼ì˜ í–¥ê¸°** - ì»¤í”¼ì˜ í’ë¯¸ì™€ í–¥ì„ ê°•ì¡°í•œ ì´ë¦„\n",
      "4. **ì»¤í”¼ ì´ì•¼ê¸°** - ê° ì»¤í”¼ì˜ ë°°ê²½ê³¼ ìŠ¤í† ë¦¬ë¥¼ ê°•ì¡°í•˜ëŠ” ì´ë¦„\n",
      "5. **í•œ ì”ì˜ ì—¬ìœ ** - ì—¬ìœ ë¡œìš´ ì»¤í”¼ íƒ€ì„ì„ ìƒì§•í•˜ëŠ” ì´ë¦„\n",
      "6. **ì»¤í”¼ ê³µë°©** - ìˆ˜ì œ ì»¤í”¼ì˜ ëŠë‚Œì„ ì£¼ëŠ” ì´ë¦„\n",
      "7. **ì»¤í”¼ ë§ˆì„** - ë‹¤ì–‘í•œ ì»¤í”¼ë¥¼ ì œê³µí•˜ëŠ” ëŠë‚Œì„ ì£¼ëŠ” ì´ë¦„\n",
      "8. **ì»¤í”¼ì˜ ë¯¸ì†Œ** - ì¦ê±°ìš´ ì»¤í”¼ ê²½í—˜ì„ ê°•ì¡°í•œ ì´ë¦„\n",
      "9. **ì»¤í”¼ì˜ ì‹œê°„** - ì»¤í”¼ì™€ í•¨ê»˜í•˜ëŠ” ì†Œì¤‘í•œ ì‹œê°„ì„ ê°•ì¡°í•œ ì´ë¦„\n",
      "10. **ì»¤í”¼ì˜ ì˜ˆìˆ ** - ì»¤í”¼ë¥¼ ì˜ˆìˆ ë¡œ í‘œí˜„í•˜ëŠ” ëŠë‚Œì˜ ì´ë¦„\n",
      "\n",
      "ì´ ì¤‘ì—ì„œ ë§ˆìŒì— ë“œëŠ” ì´ë¦„ì´ ìˆê±°ë‚˜, ì¡°í•©í•˜ì—¬ ìƒˆë¡œìš´ ì´ë¦„ì„ ë§Œë“¤ì–´ë³´ëŠ” ê²ƒë„ ì¢‹ìŠµë‹ˆë‹¤!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "parser = StrOutputParser()\n",
    "parsed_text = parser.invoke(response)  # ChatOpenAIì˜ ì‘ë‹µ ê°ì²´ë¥¼ íŒŒì‹±\n",
    "print(parsed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c6d85585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì‘ë‹µ1: ì£„ì†¡í•˜ì§€ë§Œ, ì‹¤ì‹œê°„ ë‚ ì”¨ ì •ë³´ë¥¼ ì œê³µí•  ìˆ˜ëŠ” ì—†ìŠµë‹ˆë‹¤. ...\n",
      "ì‘ë‹µ2: íŒŒì´ì¬ì—ì„œ ë¦¬ìŠ¤íŠ¸ë¥¼ ë§Œë“œëŠ” ë°©ë²•ì€ ì—¬ëŸ¬ ê°€ì§€ê°€ ìˆìŠµë‹ˆë‹¤ ...\n",
      "ì´ í† í° ìˆ˜: 567\n",
      "í”„ë¡¬í”„íŠ¸ í† í°: 39\n",
      "ì‘ë‹µ í† í°: 528\n",
      "ì´ ë¹„ìš© (USD): $0.000323\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.callbacks import get_openai_callback\n",
    "\n",
    "with get_openai_callback() as cb:\n",
    "    # ì²« ë²ˆì§¸ í˜¸ì¶œ\n",
    "    res1 = llm.invoke(\"ì„œìš¸ì˜ ì˜¤ëŠ˜ ë‚ ì”¨ëŠ” ì–´ë–¤ì§€ ì•Œë ¤ì¤˜.\")  # í”„ë¡¬í”„íŠ¸ ì˜ˆì‹œ\n",
    "    print(\"ì‘ë‹µ1:\", res1.content[:30], \"...\")  # ì‘ë‹µ ì¼ë¶€ ì¶œë ¥ (ê¸¸ ê²½ìš° ì˜ë¼ë‚´ê¸°)\n",
    "    # ë‘ ë²ˆì§¸ í˜¸ì¶œ\n",
    "    res2 = llm.invoke(\"íŒŒì´ì¬ìœ¼ë¡œ ë¦¬ìŠ¤íŠ¸ ë§Œë“œëŠ” ë°©ë²• ì˜ˆì‹œë¥¼ ì•Œë ¤ì¤˜.\")\n",
    "    print(\"ì‘ë‹µ2:\", res2.content[:30], \"...\")\n",
    "\n",
    "# ì½œë°± cbì—ëŠ” ë¸”ë¡ ë‚´ ì „ì²´ í† í° ì‚¬ìš©ëŸ‰ì´ ëˆ„ì ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\n",
    "print(f\"ì´ í† í° ìˆ˜: {cb.total_tokens}\")\n",
    "print(f\"í”„ë¡¬í”„íŠ¸ í† í°: {cb.prompt_tokens}\")\n",
    "print(f\"ì‘ë‹µ í† í°: {cb.completion_tokens}\")\n",
    "print(f\"ì´ ë¹„ìš© (USD): ${cb.total_cost:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "af44b798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì‘ë‹µ1: ë¬¼ê³ ê¸° ë‘ ë§ˆë¦¬ê°€ ìˆ˜ì˜ì„ í•˜ê³  ìˆì—ˆì–´ìš”. í•œ ë§ˆë¦¬ê°€ ë‹¤ë¥¸ ë§ˆë¦¬ì—ê²Œ ë§í–ˆì–´ìš”. \"ì•¼, ë¬¼ì´ ì™œ ì´ë ‡ê²Œ ì§œ?\" ê·¸ëŸ¬ì ë‹¤ë¥¸ ë¬¼ê³ ê¸°ê°€ ëŒ€ë‹µí–ˆì–´ìš”. \"ë„ˆëŠ” ì†Œê¸ˆë¬¼ì—ì„œ íƒœì–´ë‚¬ì–ì•„!\" \n",
      "\n",
      "ì´í•´ê°€ ì•ˆ ë˜ë©´, ë¬¼ê³ ê¸°ëŠ” ì†Œê¸ˆë¬¼ì—ì„œ ì‚´ê¸° ë•Œë¬¸ì— ì§  ë¬¼ì´ ìµìˆ™í•˜ë‹¤ëŠ” ê±°ì˜ˆìš”! ğŸ˜„ ì‹œê°„:1.9352810382843018\n",
      "ì‘ë‹µ2: ë¬¼ê³ ê¸° ë‘ ë§ˆë¦¬ê°€ ìˆ˜ì˜ì„ í•˜ê³  ìˆì—ˆì–´ìš”. í•œ ë§ˆë¦¬ê°€ ë‹¤ë¥¸ ë§ˆë¦¬ì—ê²Œ ë§í–ˆì–´ìš”. \"ì•¼, ë¬¼ì´ ì™œ ì´ë ‡ê²Œ ì§œ?\" ê·¸ëŸ¬ì ë‹¤ë¥¸ ë¬¼ê³ ê¸°ê°€ ëŒ€ë‹µí–ˆì–´ìš”. \"ë„ˆëŠ” ì†Œê¸ˆë¬¼ì—ì„œ íƒœì–´ë‚¬ì–ì•„!\" \n",
      "\n",
      "ì´í•´ê°€ ì•ˆ ë˜ë©´, ë¬¼ê³ ê¸°ëŠ” ì†Œê¸ˆë¬¼ì—ì„œ ì‚´ê¸° ë•Œë¬¸ì— ì§  ë¬¼ì´ ìµìˆ™í•˜ë‹¤ëŠ” ê±°ì˜ˆìš”! ğŸ˜„ ì‹œê°„:0.0\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.caches import InMemoryCache\n",
    "from langchain_core.globals import set_llm_cache\n",
    "import time\n",
    "\n",
    "# InMemoryCache ì„¤ì •\n",
    "set_llm_cache(InMemoryCache())  # ìºì‹œ í™œì„±í™”\n",
    "\n",
    "query = \"ì›ƒê¸´ì• ê¸° í•˜ë‚˜ í•´ì¤˜\"  # ë™ì¼í•œ ì§ˆë¬¸ì„ ë‘ ë²ˆ ë³´ë‚¼ ì˜ˆì •\n",
    "# ì²« ë²ˆì§¸ í˜¸ì¶œ (ìºì‹œì— ì—†ë‹¤ë©´ API í˜¸ì¶œ ë°œìƒ)\n",
    "start = time.time();\n",
    "result1 = llm.invoke(query)\n",
    "end = time.time();\n",
    "print(f\"ì‘ë‹µ1: {result1.content} ì‹œê°„:{end-start}\")\n",
    "\n",
    "# ë‘ ë²ˆì§¸ í˜¸ì¶œ (ë™ì¼í•œ query, ìºì‹œ íˆíŠ¸ ì‹œ API ë¯¸í˜¸ì¶œ)\n",
    "start = time.time();\n",
    "result2 = llm.invoke(\"ì›ƒê¸´ì• ê¸° í•˜ë‚˜ í•´ì¤˜\")\n",
    "end = time.time();\n",
    "print(f\"ì‘ë‹µ2: {result2.content} ì‹œê°„:{end-start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5d62cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì‹œê°„:0.0010066032409667969\n",
      "ì´ í† í° ìˆ˜: 410\n",
      "í”„ë¡¬í”„íŠ¸ í† í°: 16\n",
      "ì‘ë‹µ í† í°: 394\n",
      "ë¹„ìš©: $0.000239\n",
      "ì‹œê°„:0.0\n",
      "ì´ í† í° ìˆ˜: 410\n",
      "í”„ë¡¬í”„íŠ¸ í† í°: 16\n",
      "ì‘ë‹µ í† í°: 394\n",
      "ë¹„ìš©: $0.000239\n"
     ]
    }
   ],
   "source": [
    "# ìºì‰¬ ì„¤ì • ë° ë¹„ìš©ê³¼ ì‘ë‹µì‹œê°„ ë¹„êµ\n",
    "query = 'ìˆ™ë©´ì„ ì·¨í•˜ëŠ” ë°©ë²•ì„ ì•Œë ¤ì¤˜'\n",
    "# get_openai_callback()ë¥¼ ì‚¬ìš©í•˜ì—¬ ë¹„ìš© ì¸¡ì •\n",
    "with get_openai_callback() as cb:\n",
    "    start = time.time()\n",
    "    result1 = llm.invoke(query)\n",
    "    end = time.time()\n",
    "    print(f'ì‘ë‹µ1: {result1.content} ì‹œê°„:{end-start}')\n",
    "    print(f'ì‹œê°„:{end-start}')\n",
    "    print(f\"ì´ í† í° ìˆ˜: {cb.total_tokens}\")\n",
    "    print(f\"í”„ë¡¬í”„íŠ¸ í† í°: {cb.prompt_tokens}\")\n",
    "    print(f\"ì‘ë‹µ í† í°: {cb.completion_tokens}\")\n",
    "    print(f\"ë¹„ìš©: ${cb.total_cost:.6f}\")\n",
    "# ë‘ ë²ˆì§¸ í˜¸ì¶œ (ìºì‹œ ì‚¬ìš©)  ì‹¤ì œ ë¹„ìš© ë°œìƒì•ˆë¨... \n",
    "with get_openai_callback() as cb:\n",
    "    start = time.time()\n",
    "    result2 = llm.invoke(query)\n",
    "    end = time.time()    \n",
    "    print(f'ì‘ë‹µ1: {result1.content} ì‹œê°„:{end-start}')\n",
    "    print(f'ì‹œê°„:{end-start}')\n",
    "    print(f\"ì´ í† í° ìˆ˜: {cb.total_tokens}\")\n",
    "    print(f\"í”„ë¡¬í”„íŠ¸ í† í°: {cb.prompt_tokens}\")\n",
    "    print(f\"ì‘ë‹µ í† í°: {cb.completion_tokens}\")\n",
    "    print(f\"ë¹„ìš©: ${cb.total_cost:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef9e33b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_part_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
