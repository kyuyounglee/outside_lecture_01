{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "acf45ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-core in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_1\\lib\\site-packages (0.3.61)\n",
      "Requirement already satisfied: langchain in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_1\\lib\\site-packages (0.3.25)\n",
      "Requirement already satisfied: langchain-openai in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_1\\lib\\site-packages (0.3.18)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_1\\lib\\site-packages (1.1.0)\n",
      "Collecting langchain_community\n",
      "  Downloading langchain_community-0.3.24-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.126 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_1\\lib\\site-packages (from langchain-core) (0.3.42)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_1\\lib\\site-packages (from langchain-core) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_1\\lib\\site-packages (from langchain-core) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_1\\lib\\site-packages (from langchain-core) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_1\\lib\\site-packages (from langchain-core) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_1\\lib\\site-packages (from langchain-core) (4.13.2)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_1\\lib\\site-packages (from langchain-core) (2.11.5)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_1\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_1\\lib\\site-packages (from langsmith<0.4,>=0.1.126->langchain-core) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_1\\lib\\site-packages (from langsmith<0.4,>=0.1.126->langchain-core) (3.10.18)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_1\\lib\\site-packages (from langsmith<0.4,>=0.1.126->langchain-core) (2.32.3)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_1\\lib\\site-packages (from langsmith<0.4,>=0.1.126->langchain-core) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_1\\lib\\site-packages (from langsmith<0.4,>=0.1.126->langchain-core) (0.23.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_1\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.126->langchain-core) (4.9.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_1\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.126->langchain-core) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_1\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.126->langchain-core) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_1\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.126->langchain-core) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_1\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.126->langchain-core) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_1\\lib\\site-packages (from pydantic>=2.7.4->langchain-core) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_1\\lib\\site-packages (from pydantic>=2.7.4->langchain-core) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_1\\lib\\site-packages (from pydantic>=2.7.4->langchain-core) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_1\\lib\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.126->langchain-core) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_1\\lib\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.126->langchain-core) (2.4.0)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_1\\lib\\site-packages (from langchain) (0.3.8)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_1\\lib\\site-packages (from langchain) (2.0.41)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_1\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.2)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.68.2 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_1\\lib\\site-packages (from langchain-openai) (1.82.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_1\\lib\\site-packages (from langchain-openai) (0.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_1\\lib\\site-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_1\\lib\\site-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (0.10.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_1\\lib\\site-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_1\\lib\\site-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (4.67.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_1\\lib\\site-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain_community)\n",
      "  Downloading aiohttp-3.11.18-cp312-cp312-win_amd64.whl.metadata (8.0 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
      "  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
      "  Using cached pydantic_settings-2.9.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain_community)\n",
      "  Using cached httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting numpy>=1.26.2 (from langchain_community)\n",
      "  Downloading numpy-2.2.6-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Using cached aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_1\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Using cached frozenlist-1.6.0-cp312-cp312-win_amd64.whl.metadata (16 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Downloading multidict-6.4.4-cp312-cp312-win_amd64.whl.metadata (5.5 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Using cached propcache-0.3.1-cp312-cp312-win_amd64.whl.metadata (11 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.3->langchain_community)\n",
      "  Using cached yarl-1.20.0-cp312-cp312-win_amd64.whl.metadata (74 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Using cached marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\511-17\\miniconda3\\envs\\langchain_part_1\\lib\\site-packages (from tqdm>4->openai<2.0.0,>=1.68.2->langchain-openai) (0.4.6)\n",
      "Downloading langchain_community-0.3.24-py3-none-any.whl (2.5 MB)\n",
      "   ---------------------------------------- 0.0/2.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.5/2.5 MB 73.1 MB/s eta 0:00:00\n",
      "Downloading aiohttp-3.11.18-cp312-cp312-win_amd64.whl (439 kB)\n",
      "Using cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Using cached httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Using cached marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Downloading multidict-6.4.4-cp312-cp312-win_amd64.whl (38 kB)\n",
      "Using cached pydantic_settings-2.9.1-py3-none-any.whl (44 kB)\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Using cached yarl-1.20.0-cp312-cp312-win_amd64.whl (92 kB)\n",
      "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Using cached aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached frozenlist-1.6.0-cp312-cp312-win_amd64.whl (120 kB)\n",
      "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Downloading numpy-2.2.6-cp312-cp312-win_amd64.whl (12.6 MB)\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ----------------------------- ---------- 9.4/12.6 MB 84.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.6/12.6 MB 37.7 MB/s eta 0:00:00\n",
      "Using cached propcache-0.3.1-cp312-cp312-win_amd64.whl (44 kB)\n",
      "Installing collected packages: propcache, numpy, mypy-extensions, multidict, marshmallow, httpx-sse, frozenlist, aiohappyeyeballs, yarl, typing-inspect, aiosignal, pydantic-settings, dataclasses-json, aiohttp, langchain_community\n",
      "\n",
      "   -- -------------------------------------  1/15 [numpy]\n",
      "   -- -------------------------------------  1/15 [numpy]\n",
      "   -- -------------------------------------  1/15 [numpy]\n",
      "   -- -------------------------------------  1/15 [numpy]\n",
      "   -- -------------------------------------  1/15 [numpy]\n",
      "   -- -------------------------------------  1/15 [numpy]\n",
      "   -- -------------------------------------  1/15 [numpy]\n",
      "   -- -------------------------------------  1/15 [numpy]\n",
      "   -- -------------------------------------  1/15 [numpy]\n",
      "   -- -------------------------------------  1/15 [numpy]\n",
      "   -------- -------------------------------  3/15 [multidict]\n",
      "   ----------------------------- ---------- 11/15 [pydantic-settings]\n",
      "   ---------------------------------- ----- 13/15 [aiohttp]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ------------------------------------- -- 14/15 [langchain_community]\n",
      "   ---------------------------------------- 15/15 [langchain_community]\n",
      "\n",
      "Successfully installed aiohappyeyeballs-2.6.1 aiohttp-3.11.18 aiosignal-1.3.2 dataclasses-json-0.6.7 frozenlist-1.6.0 httpx-sse-0.4.0 langchain_community-0.3.24 marshmallow-3.26.1 multidict-6.4.4 mypy-extensions-1.1.0 numpy-2.2.6 propcache-0.3.1 pydantic-settings-2.9.1 typing-inspect-0.9.0 yarl-1.20.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain-core langchain langchain-openai python-dotenv langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093592e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sk-proj-Do'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "# .env 파일을 만들어서 OPENAI_API_KEY= ... 형태로 작성되어야 함\n",
    "load_dotenv()\n",
    "os.getenv('OPENAI_API_KEY')[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c334fe91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is a good name for a company that makes coffee?\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# 프롬프트 템플릿 정의: {product} 부분이 이후에 채워질 플레이스홀더입니다.\n",
    "template = \"What is a good name for a company that makes {product}?\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# 템플릿에 값을 채워 실제 프롬프트 생성\n",
    "formatted_prompt = prompt.format(product=\"coffee\")\n",
    "print(formatted_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db5170e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "커피라는 만드는 회사 이름으로 어떤게 좋을까?\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# 프롬프트 템플릿 정의: {product} 부분이 이후에 채워질 플레이스홀더입니다.\n",
    "template = \"{product}라는 만드는 회사 이름으로 어떤게 좋을까?\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# 템플릿에 값을 채워 실제 프롬프트 생성\n",
    "formatted_prompt = prompt.format(product=\"커피\")\n",
    "print(formatted_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88e494a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='커피 회사 이름을 정할 때는 브랜드의 이미지, 타겟 고객, 그리고 제품의 특징을 고려하는 것이 중요합니다. 다음은 몇 가지 아이디어입니다:\\n\\n1. **커피의 정원** - 자연 친화적인 느낌을 주는 이름\\n2. **아침의 한 잔** - 아침에 커피를 즐기는 사람들을 겨냥한 이름\\n3. **커피의 향기** - 커피의 풍미와 향을 강조한 이름\\n4. **커피 이야기** - 각 커피의 배경과 스토리를 강조하는 이름\\n5. **한 잔의 여유** - 여유로운 커피 타임을 상징하는 이름\\n6. **커피 공방** - 수제 커피의 느낌을 주는 이름\\n7. **커피 마을** - 다양한 커피를 제공하는 느낌을 주는 이름\\n8. **커피의 미소** - 즐거운 커피 경험을 강조하는 이름\\n9. **커피의 시간** - 커피와 함께하는 특별한 순간을 강조하는 이름\\n10. **커피의 예술** - 커피를 예술로 표현하는 느낌의 이름\\n\\n이 중에서 마음에 드는 이름이 있거나, 조합하여 새로운 이름을 만들어보는 것도 좋습니다!' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 282, 'prompt_tokens': 20, 'total_tokens': 302, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_54eb4bd693', 'id': 'chatcmpl-BaacNWqfS05J6oWT2MucRK0jw4FiY', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None} id='run--32a0037c-19b1-4ed4-b570-e12e49bc4314-0' usage_metadata={'input_tokens': 20, 'output_tokens': 282, 'total_tokens': 302, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# OpenAI 챗 모델 래퍼 생성 (GPT-4o-mini 모델 사용, 온도=0으로 설정하여 결정론적 응답)\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "# 예시 메시지를 모델에 보내보기 (역할: human, 내용: 인사말)\n",
    "response = llm.invoke([(\"human\", formatted_prompt)])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b39f7787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "커피 회사 이름을 정할 때는 브랜드의 이미지, 타겟 고객, 그리고 제품의 특징을 고려하는 것이 중요합니다. 다음은 몇 가지 아이디어입니다:\n",
      "\n",
      "1. **커피의 정원** - 자연 친화적인 느낌을 주는 이름\n",
      "2. **아침의 한 잔** - 아침에 커피를 즐기는 사람들을 겨냥한 이름\n",
      "3. **커피의 향기** - 커피의 풍미와 향을 강조한 이름\n",
      "4. **커피 이야기** - 각 커피의 배경과 스토리를 강조하는 이름\n",
      "5. **한 잔의 여유** - 여유로운 커피 타임을 상징하는 이름\n",
      "6. **커피 공방** - 수제 커피의 느낌을 주는 이름\n",
      "7. **커피 마을** - 다양한 커피를 제공하는 느낌을 주는 이름\n",
      "8. **커피의 미소** - 즐거운 커피 경험을 강조한 이름\n",
      "9. **커피의 시간** - 커피와 함께하는 소중한 시간을 강조한 이름\n",
      "10. **커피의 예술** - 커피를 예술로 표현하는 느낌의 이름\n",
      "\n",
      "이 중에서 마음에 드는 이름이 있거나, 조합하여 새로운 이름을 만들어보는 것도 좋습니다!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "parser = StrOutputParser()\n",
    "parsed_text = parser.invoke(response)  # ChatOpenAI의 응답 객체를 파싱\n",
    "print(parsed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c6d85585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "응답1: 죄송하지만, 실시간 날씨 정보를 제공할 수는 없습니다. ...\n",
      "응답2: 파이썬에서 리스트를 만드는 방법은 여러 가지가 있습니다 ...\n",
      "총 토큰 수: 567\n",
      "프롬프트 토큰: 39\n",
      "응답 토큰: 528\n",
      "총 비용 (USD): $0.000323\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.callbacks import get_openai_callback\n",
    "\n",
    "with get_openai_callback() as cb:\n",
    "    # 첫 번째 호출\n",
    "    res1 = llm.invoke(\"서울의 오늘 날씨는 어떤지 알려줘.\")  # 프롬프트 예시\n",
    "    print(\"응답1:\", res1.content[:30], \"...\")  # 응답 일부 출력 (길 경우 잘라내기)\n",
    "    # 두 번째 호출\n",
    "    res2 = llm.invoke(\"파이썬으로 리스트 만드는 방법 예시를 알려줘.\")\n",
    "    print(\"응답2:\", res2.content[:30], \"...\")\n",
    "\n",
    "# 콜백 cb에는 블록 내 전체 토큰 사용량이 누적되어 있습니다.\n",
    "print(f\"총 토큰 수: {cb.total_tokens}\")\n",
    "print(f\"프롬프트 토큰: {cb.prompt_tokens}\")\n",
    "print(f\"응답 토큰: {cb.completion_tokens}\")\n",
    "print(f\"총 비용 (USD): ${cb.total_cost:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "af44b798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "응답1: 물고기 두 마리가 수영을 하고 있었어요. 한 마리가 다른 마리에게 말했어요. \"야, 물이 왜 이렇게 짜?\" 그러자 다른 물고기가 대답했어요. \"너는 소금물에서 태어났잖아!\" \n",
      "\n",
      "이해가 안 되면, 물고기는 소금물에서 살기 때문에 짠 물이 익숙하다는 거예요! 😄 시간:1.9352810382843018\n",
      "응답2: 물고기 두 마리가 수영을 하고 있었어요. 한 마리가 다른 마리에게 말했어요. \"야, 물이 왜 이렇게 짜?\" 그러자 다른 물고기가 대답했어요. \"너는 소금물에서 태어났잖아!\" \n",
      "\n",
      "이해가 안 되면, 물고기는 소금물에서 살기 때문에 짠 물이 익숙하다는 거예요! 😄 시간:0.0\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.caches import InMemoryCache\n",
    "from langchain_core.globals import set_llm_cache\n",
    "import time\n",
    "\n",
    "# InMemoryCache 설정\n",
    "set_llm_cache(InMemoryCache())  # 캐시 활성화\n",
    "\n",
    "query = \"웃긴애기 하나 해줘\"  # 동일한 질문을 두 번 보낼 예정\n",
    "# 첫 번째 호출 (캐시에 없다면 API 호출 발생)\n",
    "start = time.time();\n",
    "result1 = llm.invoke(query)\n",
    "end = time.time();\n",
    "print(f\"응답1: {result1.content} 시간:{end-start}\")\n",
    "\n",
    "# 두 번째 호출 (동일한 query, 캐시 히트 시 API 미호출)\n",
    "start = time.time();\n",
    "result2 = llm.invoke(\"웃긴애기 하나 해줘\")\n",
    "end = time.time();\n",
    "print(f\"응답2: {result2.content} 시간:{end-start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5d62cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "시간:0.0010066032409667969\n",
      "총 토큰 수: 410\n",
      "프롬프트 토큰: 16\n",
      "응답 토큰: 394\n",
      "비용: $0.000239\n",
      "시간:0.0\n",
      "총 토큰 수: 410\n",
      "프롬프트 토큰: 16\n",
      "응답 토큰: 394\n",
      "비용: $0.000239\n"
     ]
    }
   ],
   "source": [
    "# 캐쉬 설정 및 비용과 응답시간 비교\n",
    "query = '숙면을 취하는 방법을 알려줘'\n",
    "# get_openai_callback()를 사용하여 비용 측정\n",
    "with get_openai_callback() as cb:\n",
    "    start = time.time()\n",
    "    result1 = llm.invoke(query)\n",
    "    end = time.time()\n",
    "    print(f'응답1: {result1.content} 시간:{end-start}')\n",
    "    print(f'시간:{end-start}')\n",
    "    print(f\"총 토큰 수: {cb.total_tokens}\")\n",
    "    print(f\"프롬프트 토큰: {cb.prompt_tokens}\")\n",
    "    print(f\"응답 토큰: {cb.completion_tokens}\")\n",
    "    print(f\"비용: ${cb.total_cost:.6f}\")\n",
    "# 두 번째 호출 (캐시 사용)  실제 비용 발생안됨... \n",
    "with get_openai_callback() as cb:\n",
    "    start = time.time()\n",
    "    result2 = llm.invoke(query)\n",
    "    end = time.time()    \n",
    "    print(f'응답1: {result1.content} 시간:{end-start}')\n",
    "    print(f'시간:{end-start}')\n",
    "    print(f\"총 토큰 수: {cb.total_tokens}\")\n",
    "    print(f\"프롬프트 토큰: {cb.prompt_tokens}\")\n",
    "    print(f\"응답 토큰: {cb.completion_tokens}\")\n",
    "    print(f\"비용: ${cb.total_cost:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef9e33b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_part_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
